\chapter{Implementierung} \label{implementation}

Dieses Kapitel erläutert den Implementierungsvorgang des Java Medical Imaging Toolkits. Besonderer Wert wird auf die Umsetzung der Blattknoten wie in Kapitel \ref{architecture} Abschnitt \ref{jmedikit_structure} gelegt, da diese Anwendungsteile direkt mit dem Anwender in Aktion treten.\\
Nach einer Beschreibung wie die DICOM-Objekte repräsentiert werden, wird umfangreich auf die Bilddarstellung und Manipulation eingegangen.

\section{Implementierung der DICOM-Objekte}

Die beiden Schnittstellen \textit{IDicomData} und \textit{IDicomImageData} bilden die Grundlagen aller DICOM-Objekte die vom jMediKit erzeugt werden und sind gleichzeitig die einzige Kommunikationsmöglichkeit zu den externen Bibliotheken. Der abstrakte Adapter \textit{ADicomObject} stellt die Funktionen beider Schnittstellen zur Verfügung. Die wichtigsten Methoden stellen das Auslesen der Pixel und den einzelnen Tags eines DICOM-Objekts dar. \\
Das eingebundene \textit{dcm4che} bietet neben der Verarbeitung von DICOM-Objekten auch eine Implementierung des Kommunikations- und Speicherstandards von DICOM an. Während der aktuellen Entwicklung wurde allerdings nur ein Bruchteil der DICOM-Verarbeitung zur Erfüllung der Anforderungen benötigt und der Kommunikations- und Speicherprozess fand keine Beachtung. Bei einer Implementierung sollte dennoch eine zukünftige Erweiterung im Auge behalten werden. Dabei soll ebenso das Open-Closed-Prinzip Beachtung finden.\\
Hierbei werden die Schnittstellen in fachspezifische Domänen eingeteilt. Das bedeutet \textit{IDicomData} ist für das Verarbeiten der Tags zuständig, während \textit{IDicomImageData} ausschließlich Bilddaten verarbeitet. Für weitere Versionen können weitere Domänen implementiert werden, wie zum Beispiel eine Schnittstelle \textit{IDicomNetworkData}. Der Adapter vereint die Domänen zu einem vollen DICOM-Objekt. 

\section{Der DicomBrowser}
Der DicomBrowser ist der zentrale Part zum Transfer der DICOM-Dateien aus dem Dateisystem zu les- und verarbeitbaren DICOM-Objekten. Abbildung \ref{dicombrowser} zeigt die Darstellung nach dem Einlesenen eines Ordners mit DICOM-Dateien. Die Repräsentation entspricht dem ER-Modell aus Kapitel \ref{grundlagen} Abschnitt \ref{grundlagen:iod}. Der Knoten $\backslash$ symbolisiert die Wurzel. \textit{BRAINX}\footnote{Beispieldatensätze verfremden die tätslchlichen Patientennamen. Originale Datensätze hätten die Form \textit{Nachname\^{}Vorname}} steht für den Patientenname, gefolgt von in diesem Beispiel einer Studie, die wiederum aus sieben Serien besteht. Die einzelnen DICOM-Objekte als Blattknoten werden aufgrund der Übersichtlichkeit nicht angezeigt.\\
Die Repräsentation der Dateien ist nicht immer geordnet wie es das ER-Modell vorgibt und man kann nicht von einer sortierten Ordnerstruktur ausgehen. Die PACS-Software \textit{dcm4chee} ordnet die Daten beispielsweise nach dem Aufnahmedatum. Es wird eine Datenstruktur benötigt, die der DICOM Object Definiton entspricht.

\begin{figure}[htbp]
  \vspace{0.5cm}
  \centering
  \fbox{\includegraphics[angle=0,width=9cm]{./img/dicombrowser.png}}
   \caption{Die Baumansicht des DICOM-Browsers mit geladenen Objekten}
  \label{dicombrowser}
  \vspace{0.5cm}
\end{figure}

\subsection{Die Baumstruktur} \label{treestructure}
Sowohl die Anzeige, als auch die interne Behandlung der Daten soll so nah wie möglich an den DICOM-Standard angelehnt sein und unabhängig von der Auslieferung\footnote{Unabhängig davon, ob Dateien von der Festplatte geladen oder über das Netzwerk bezogen werden.} der Dateien die Struktur des ER-Modells haben.\\
Ein Baum als Datenstruktur erfüllt die grundlegende Repräsentation mit den verschiedenen Knotentypen aus Patientenname, Studien, Serien und den DICOM-Objekten.\\
Dadurch ergibt sich mit der Wurzel eine Höhe von
\begin{equation}
h = max(4)
\label{baumheight}
\end{equation}
und folgende konkrete Höhen der Knotentypen.
\begin{equation}
h_{Root} = 0 \qquad
h_{Patienenname} = 1 \qquad 
h_{Study} = 2 \qquad
h_{Series} = 3 \qquad
h_{Oject} = 4
\label{heights}
\end{equation}

Der minimale Baum besteht nur aus der Wurzel und hat die Höhe $h_{min} = 0$. Nach der Multiplizität des Modells aus Abschnitt \ref{grundlagen:iod} hat der Baum, sobald ein Patientenname eingefügt wird, eine minimale Höhe von $h_{min} = 3$, da Patientenname und Study jeweils mindestens ein Kindelement enthalten. Die Breite des Baums ist unbestimmt, da Knoten eine beliebige Anzahl an Kindern besitzen können. Abbildung \ref{treeexample} zeigt einen Baum, wie er in der Anwendung repräsentiert werden könnte. Der Baum enthält alle Knotentypen von \textit{Patientname} bis \textit{Object}-Ebene.\\
Zwei Klassen des Quelltextes liefern die Basis des Baums:

\begin{itemize}
\item \textbf{DicomTreeRepository}\\
	  Diese Klasse repräsentiert den Baum. Sie enthält den Wurzelknoten, und einige graphentypische Operationen. Der Baum kann nach Knoten durchsucht werden und hat eine Funktion zum Einfügen neuer Knoten. Eine Löschfunktion wurde nicht implementiert, da der Baum nicht vom Benutzer manipuliert werden soll. Das Einfügen soll nur zum initialen Einlesen aufgerufen werden.
\item \textbf{ADicomTreeItem}\\
	  \textit{ADicomTreeItem} bilden die Knoten des Baumes. Jede Instanz besitzt eine Identifikationsnummer und kennt sowohl das Elternelement, als auch die Kindknoten. 
\end{itemize}

\tikzstyle{every node}=[draw=black,thick,anchor=south, align=center]
%\tikzstyle{selected}=[draw=red,fill=red!30]
\tikzstyle{optional}=[dashed,fill=gray!50]
\begin{figure}[htbp]
\centering
\caption{Beispielhafte Darstellung eines Baumes mit $h = 4$ in der Implementierung}
\label{treeexample}
\begin{tikzpicture}[level distance=1.5cm,
  level 1/.style={sibling distance=6cm},
  level 2/.style={sibling distance=5cm},
  level 4/.style={sibling distance = 3cm, level distance = 2cm},
   level 5/.style={sibling distance=1cm},]
  \node {$\backslash$}
    child { node{Patientname}
      child { node{Study}
        child {node{Series}
        	child {node{Object}}
        	child {node{Object}}
        }
        child {node{Series}
          child {node{Object}}
        }
      }
    }
    child { node{Patientname}
    	child{ node{Study}
    	  child{ node{Series}
    	  	child {node{Object}}
    	  	child {node{Object}}
    	  }
    	}
    };
\end{tikzpicture}
\end{figure}

Da nun die Datenstruktur bestimmt ist, fehlt das Vorgehen zur Sortierung der Daten. Abbildung \ref{filesystemrep} in Abschnitt \ref{grundlagen:dicom} zeigt eine mögliche Dateistruktur. Das liefert allerdings keine Sicherheit, dass die Dateien immer vorsortiert zur Verfügung stehen. SLiegen alle DICOM-Dateien in einem Ordner, wäre eine Einteilung in Patienten und Serien etc. nicht mehr möglich.\\
Wie bereits in Abschnitt \ref{grundlagen:dicom} beschrieben besitzt jeder Patient, jede Studie und jede Serie eine eigene eindeutige Identifikationsnummer(UID), die eine modellgerechte Sortierung ermöglicht. Die Tags, die diese UIDs enthalten sind \textit{Patient ID}, \textit{Study Instace UID}, \textit{Series Instance UID} und \textit{SOP Instance UID}.\\
Jede Datei repräsentiert ein Blatt im Baum und somit ein DICOM-Objekt. Dadurch muss die abstrakte Klasse ADicomObjekt aus der Architekturbeschreibung aus Kapitel \ref{architecture} Abschnitt \ref{adapter_dependencies} angepasst werden und erweitert die abstrakte Superklasse ADicomTreeItem. Somit erben alle DICOM-Objekte die Eigenschaften eines Knoten im Baum. Zur weiteren Klassifizierung der Knoten werden die Klassen \textit{DicomPatientItem}, \textit{DicomStudyItem} und \textit{DicomSeriesItem}, die alle von \textit{ADicomTreeItem} erben, eingesetzt.
Bei der Instantiierung des DICOM-Objekts wird direkt die UID über \textit{SOP Instance UID} zugewiesen. Als nächster Schritt wird aus dem DICOM-Objekt der Pfad von der Wurzel zum Objekt ermittelt. Dazu werden \textit{Patient ID}, \textit{Study Instace UID} und \textit{Series Instance UID} des Objekts ausgelesen. Nun wird der Baum nach den entsprechenden Objekten und den UIDs durchsucht. Sind diese nicht vorhanden, wird das zugehörige Objekt erzeugt und in den Baum eingefügt, bis letztendlich das DICOM-Objekt als Blatt eingehängt werden kann.\\
Mittels dieser Sortierung entsprechen die Elemente im DicomBrowser der Darstellung des ER-Modells.


\section{Repräsentation der Pixeldaten}

Ganzzahlige Datentypen in Java (\textit{byte}, \textit{short}, \textit{int}, \textit{long}) werden im Zweierkomplement kodiert\cite[S.106]{java:insel}]. Dadurch sind nur Werte im Bereich von $[-2^{BIT-1}, 2^{BIT-1}-1]$. Das entspricht beim Datentyp \textit{short} dem Intervall von $[-2^{15}, 2^{15}-1] \rightarrow [-32768, 32767]$.\\
Medizinische Grauwertbilder besitzen meist eine Tiefe von 8-, 12- und 16-Bit. Zusätzlich bestimmt der DICOM-Tag \textit{PixelRepresentation}, ob Pixelwerte vorzeichenbehaftet sind. Durch diese variablen Eigenschaften entstehen unterschiedliche Bildtypen. Aus dem Abschnitt \ref{grey_images} wird deutlich, dass Grauwertbilder mit einer Tiefe von 16-Bit den Bereich von $[0,65535]$ abdecken. Dadurch entsteht eine Diskrepanz zwischen dem 16-Bit Java Datentyp \textit{short} und den Grauwerten. Die Pixelwerte können vom Typ \textit{short} nicht aufgenommen werden. Das gleiche Missverhältnis entsteht bei einer Tiefe von 8-Bit. Wie in Tabelle \ref{java:datentypen} zu sehen, fasst der Datentyp \textit{byte} maximal einen Wert von 127 während der größte Pixelwert 255 entspricht. Daraus folgt, dass Grauwertbilder ohne vorzeichenbehaftete Werte (Unsigned) mit dem nächsthöheren Datentyp repräsentiert werden.

\begin{table}
    \begin{tabularx}{\textwidth}{|X|X|X|X|}
    \toprule
    \hline
    \textbf{Datentyp}         & \textbf{MIN}    & \textbf{MAX}& \textbf{Unsigned} \\ \hline
    byte 		 			  & -128					& 127 		  & 0 - 255\\ \hline
    short 		 			  & -32768				& 32767 		  	  & 	0 - 65535\\ \hline
    int						  & -2147483648		& 2147483647 		  & 0 - 4294967295\\ \hline
    long 				      & \tiny{-9223372036854775808}			& \tiny{9223372036854775807} 		  & \tiny{0 - 18446744073709551615}\\ \hline

    \bottomrule
    \end{tabularx}
    \caption {Ganzzahlige Datentypen in Java}
    \label{java:datentypen}
\end{table}

\begin{table}
    \begin{tabularx}{\textwidth}{|p{5cm}|X|X|X|X|}
    \toprule
    \hline
    \textbf{Klassenname}         & \textbf{Pixeltyp Code}    & \textbf{Bittiefe Code}& \textbf{Bittiefe DICOM-Objekt} & \textbf{Vorzeichen} \\ \hline
    UnsignedByteImage 		 	& short					& 16 		  & 8 & \O \\ \hline
    ShortImage 		 			  & short				& 16 		  	  & 	16 & ja\\ \hline
    UnsignedShortImage						  & int		& 32 		  & 16 & \O \\ \hline
    IntegerImage (Farbbild)				      & int		& 32, 8-Bit je Kanal		  & 32, 8-Bit je Kanal & \O \\ \hline

    \bottomrule
    \end{tabularx}
    \caption {Von jMediKit implementierte Bildtypen}
    \label{java:bildtypen}
\end{table}

Tabelle \ref{java:bildtypen} zeigt eine Darstellung der implementierten Bildtypen und die zugehörigen Datentypen der Pixel im Quelltext. Haben die Pixeldaten eines DICOM-Objekts eine Tiefe von 8-Bit und sind nicht vorzeichenbehaftet, wird zur Repräsentation in der Implementierung ein Array des Typs \textit{short} verwendet, um alle Werte aufnehmen zu können.\\
Der Datentyp \textit{int} könnte alle Pixelwerte eines DICOM-Objekts aufnehmen. So liegt es nahe, dass Integer durchgehend als Datentyp verwendet wird. Arbeitet man allerdings mit 8-Bittiefe ohne Vorzeichen, wird der Speicherbedarf von 16 auf 32 Bit pro Pixel verdoppelt. Daher ist es sinnvoll die Bildtypen zu kategorisieren.

\subsection{Räumliche Sortierung der Bilddaten}

Beim Erstellen des Baums aus Abschnitt \ref{treestructure} wird rekursiv das Verzeichnis durchlaufen und nach lesbaren DICOM-Objekten gesucht. Ist die Suche erfolgreich, wird das Objekt dem Baum hinzugefügt. Hierbei kann das Problem auftreten, dass Dateien in der falschen Reihenfolge importiert werden. So kann es passieren, dass ein Importvorgang abhängig vom Dateinamen Objekte dem Baum hinzufügt. Die räumliche Reihenfolge der einzelnen Schichten entspricht allerdings keineswegs dem Dateinamen\footnote{Je nach Sortierung innerhalb des Betriebssystems könnte ein Import auch nach dem Änderungsdatum erfolgen} oder anderen dateibezogenen Reihenfolgen. Dadurch wird, wie schon bei der Sortierung nach dem ER-Modell, eine Methode benötigt, mittels DICOM-Tags die korrekte Reihenfolge der Bilddaten herzustellen.\\
Der Standard verfügt über mehrere Tags, welche die richtige Reihenfolge andeuten. \textit{Instance Number} ist nach dem Standard \cite[C.7.6.1]{dicom:iod} eine Nummer, die ein Bild identifiziert. Während der Entwicklung entsprach dieser Wert der Testbilder der dargestellten Reihenfolge, jedoch ist keine Information enthalten ob diese der tatsächlichen Reihenfolge im Raum entspricht. So könnte der Wert für die Aufnahmenreihenfolge oder andere konsekutive auf- oder absteigende Folgen stehen. Dadurch ist \textit{Instance Number} nur bedingt geeignet.\\
Ein Tag, der räumliche Informationen enthält ist \textit{Slice Location}. Nach dem Standard \cite[C.7.6.2]{dicom:iod} ist dieser Wert die relative Position der Bildebene in mm. Es ist allerdings keine Information enthalten, ob die Sortierung in steigender oder fallender Reihenfolge erfolgt. Da der Tag zusätzlich nur optional vorhanden ist, kann eine Nutzung zur Bestimmung der Anordnung ausgeschlossen werden.

\begin{figure*}[htb]
%\subfigure[Keypoints]{\includegraphics[width=0.49\textwidth]{./img/basmati_keypoints.png}}\hfill
\centering
\fbox{
\subfigure[Darstellung der beiden Richtungsvektoren der Bildebene und zugehörige Normale $\vec{r} \times \vec{c}$]{\includegraphics[width=5cm]{./img/normalenvektor.pdf} \label{sort:single}}
\subfigure[Schichten entlang der Normalen $\vec{r} \times \vec{c}$]{\includegraphics[width=5cm]{./img/normalenvektorstack.pdf} \label{sort:stack}}
\subfigure[Sortierung erfolgt durch Bestimmung der dominanten Achse]{\includegraphics[width=5cm]{./img/dominantindex.pdf} \label{sort:dominant}}
}
\caption{Räumliche Sortierung der DICOM-Objekte}
\label{sort}
\end{figure*}

In der Mailingliste des Insight Segmentation and Registration Toolkits \cite{itk:mail} wird eine Berechnung über die Attribute \textit{Image Position} und \textit{Image Orientation} vorgeschlagen.
\textit{Image Position} enthält die $x$, $y$ und $z$ Koordinate in mm und \textit{Image Orientation} den Richtungskosinus\footnote{Ein Richtungskosinus beschreibt die Winkel des Vektors zu den drei Koordinatenachsen} der ersten Reihe und Spalte des Bildes in Abhängigkeit des Patienten. Diese beiden Richtungsvektoren spannen die Bildebene auf und müssen nach \cite[C.7.6.2.1.1]{dicom:iod} orthogonal zueinander sein.\\
Die Abbildungen in \ref{sort} zeigen das Koordinatensystem des Patienten als rechtshändiges System\cite[S.419]{dicom:iod}. Dieses ist um 180 Grad um die x-Achse gedreht. In Abbildung \ref{sort:single} ist die Bildebene sowie die beiden Richtungsvektoren $\vec{c}$ der ersten Spalte und $\vec{r}$ der ersten Reihe dargestellt. Mit Hilfe des Kreuzproduktes lässt sich nun die Normale der Ebene bestimmen. Die räumliche Anordnung der Schichten erfolgt entlang des Normalenvektors $\vec{r} \times \vec{c}$ (Abbildung \ref{sort:stack}). Die Richtungsvektoren könnten folgende Darstellung besitzen:

\begin{equation}
%\vec{r}=\left(\begin{array}{c} 1 \\ 0 \end{array}\right) \qquad
\vec{r}=\left(\begin{array}{c} 1 \\ 0 \\ 0 \end{array}\right) \qquad
\vec{c}=\left(\begin{array}{c} 0 \\ 1 \\ 0 \end{array}\right) \qquad
\vec{n}=\vec{r}\times\vec{c}=\left(\begin{array}{c} 0 \\ 0 \\ 1 \end{array}\right) \qquad
\vspace{0.5cm}
\label{example_vector}
\end{equation}

Nachdem die Normale $\vec{n}$ der Ebene bestimmt ist, muss der dominante Anteil des Vektors ermittelt werden. Dazu wird der maximale Betrag aus den Elementen von $ \vec{n}$ mit $|n_x|, |n_y|, |n_z|$ berechnet. Somit erhält man die Achse an der die Schichten angeordnet sind. Im Beispiel \ref{example_vector} und Abbildung \ref{sort:dominant} erfolgt die Anordnung entlang der z-Achse, da $n_z$ den dominanten Anteil von $\vec{n}$ darstellt. Ist $n_z < 0$ erfolgt die Wuchsrichtung der Schichten entlang des negativen Anteils der z-Achse. Wenn $n_z >= 0$ wachsen die Ebenen in die positive Richtung.\\
Mit Hilfe dieser Kriterien lassen sich die Bilder über den Tag \textit{Image Position} sortieren. Es ist bekannt, welche Achse die Reihenfolge im Raum symbolisiert. Beispiel \ref{example_sort} zeigt drei Vektoren mit möglichen Daten von \textit{ImagePosition}. Ist der dominante Anteil des Vektors kleiner 0, verläuft die Wuchsrichtung negativ und der größte Wert ist das erste Bild der Folge. Ist der dominante Anteil positiv, hat das erste Bild des kleinsten Wert. Da im Beispiel \ref{example_vector} $n_z >= 0$ entspricht die Sortierte Reihenfolge aus Beispiel \ref{example_sort} $\vec{b}\rightarrow\vec{a}\rightarrow\vec{c}$.

\begin{equation}
%\vec{r}=\left(\begin{array}{c} 1 \\ 0 \end{array}\right) \qquad
\vec{a}_{position}=\left(\begin{array}{c} 13.6 \\ 122 \\ 75 \end{array}\right) \qquad
\vec{b}_{position}=\left(\begin{array}{c} 13.7 \\ 121.6 \\ 65 \end{array}\right) \qquad
\vec{c}_{position}=\left(\begin{array}{c} 12.6 \\ 122.1 \\ 85 \end{array}\right) \qquad
\vspace{0.5cm}
\label{example_sort}
\end{equation}

Durch eine Implementierung des Interface \textit{Comparable\textless AImage\textgreater} in \textit{AImage} unter Berücksichtigung dieser Vorgehensweise ist eine einfache und für diesen Zweck ausreichend schnelle Sortierung der Bildebenen mögliche. Somit erfolgt die Anordnung des Baums und der Bilder unabhängig der Dateistruktur.\\
Voraussetzung für diese Umsetzung ist, dass die Bildebenen parallel zu den Koordinatenachsen verlaufen. Bei Bildreihen mit Kurven oder einem schrägen Verlauf kann keine dominante Achse bestimmt werden.

\section{Zeichnen und manipulieren der Bilddaten}

Sowohl die DICOM-Objekte, als auch Bilddaten stehen im Speicher zur Verarbeitung bereit. Dieser Abschnitt befasst sich mit der Visualisierung dieser Daten. Wie aus Kapitel \ref{architecture} Abschnitt \ref{ivp_architecture} bekannt ist, erfolgt die Darstellung der Bilder im \textit{ImageViewPart} der Anwendung. Innerhalb des Parts können bis zu vier \textit{ImageViewComposites } angezeigt werden. Diese dienen vor allem zur Bedienung des enthaltenen \textit{DicomCanvas}. So kann mit Hilfe der Scrollleiste durch den dreidimensionalen Datensatz navigiert, oder Informationen wie das Koordinatensystem angezeigt und versteckt werden. Die tatsächliche Anzeige der Bilddaten findet im Canvas-Element statt. Eine direkte Manipulation der Bilder erfolgt durch die Auswahl eines Werkzeugs.\\
Die Breite und Höhe der Zeichenfläche ist unter anderem abhängig von der Zahl der angezeigten \textit{ImageViewComposites}, der Bildschirmgröße und dessen Auflösung. Je mehr Composites angezeigt werden, desto kleiner wird der Bereich für das \textit{DicomCanvas}. So kann der Fall eintreten, dass die Dimension der Zeichenfläche nicht ausreicht, um ein Bild vollständig anzuzeigen, da das Bild größer als die zur Verfügung stehender Fläche ist. Dadurch muss dem Nutzer eine Möglichkeit gegeben werden, nicht sichtbare Details in den sichtbaren Bereich schieben zu können.\\
Neben dem Verschieben des Bildes gibt es zwei weitere essentielle Werkzeuge zur Manipulation medizinischer Bilddaten. Bei einer Darstellung in 100\% der Bildgröße sind Details nicht immer gut zu erkennen. Dadurch muss eine Skalierung des Bildes möglich sein.
Das zweite Werkzeug übernimmt die Fensterung der Grauwerte. Je nach Struktur oder Gewebe das betrachtet werden soll, müssen die Fensterungswerte individuell zu wählen sein.
Zusätzlich zu den Werkzeugen gibt es drei verschiedene Ansichten, aus denen der Benutzer wählen kann. Damit kann bestimmt werden, welche Ebene der 3D-Bilddaten angezeigt werden soll. Abbildung \ref{layers} zeigt die verschiedenen Optionen. Die einzelnen Ansichten sind die $(x,y)$-Ebene (axial), die $(x,z)$-Ebene (coronal) und die $(y,z)$-Ebene (sagittal).\\
\begin{figure*}[htb]
%\subfigure[Keypoints]{\includegraphics[width=0.49\textwidth]{./img/basmati_keypoints.png}}\hfill
\centering
\fbox{
\subfigure[Axiale Ansicht - $(x,y)$]{\includegraphics[width=5cm]{./img/axial_xy.pdf} \label{layers:axial}}
\subfigure[Coronale Ansicht - $(x,z)$]{\includegraphics[width=5cm]{./img/coronal_xz.pdf} \label{layers:coronal}}
\subfigure[Sagittale Ansicht - $(y,z)$]{\includegraphics[width=5cm]{./img/sagittal_yz.pdf} \label{layers:sagittal}}
}
\caption{Die verschiedenen Ansichten der Ebenen eines dreidimensionalen Datensatzes}
\label{layers}
\end{figure*}

Die Faktoren DICOM-Objekt, Bedienelemente der Composites, Werkzeuge und die verschiedenen Ansichten der Ebenen beeinflussen maßgeblich den Prozess der Anzeige der Bilddaten. Die Vorgehensweise wird in Abbildung \ref{imageprocess} visualisiert. Der Prozess gliedert sich in sechs zentrale Verarbeitungsblöcke und zwei Einhängepunkte(Hooks) für Werkzeuge.

\begin{figure}[htbp]
  \vspace{0.5cm}
  \centering
  \fbox{\includegraphics[angle=0,width=10cm]{./img/imageprocess.pdf}}
   \caption{Der Prozess von der Bildauswahl zur Anzeige}
  \label{imageprocess}
  \vspace{0.5cm}
\end{figure}

\begin{enumerate}
\item \textbf{Bilddaten initialisieren}\\
	Abhängig vom gewählten Index der Scrollleiste des \textit{ImageViewComposites} wird das entsprechende Bild aus dem 3D-Datensatz geladen.
\item \textbf{Koordinaten des geladenen Bildes berechnen}\\
	Wird ein Bild auf der Zeichenfläche verschoben, ändern sich die Koordinaten des Bildes. Dieser Block übernimmt die Berechnung, damit die Daten korrekt angezeigt werden.
\item \textbf{Bild interpolieren}\\
	Bei einer Skalierung ändert sich die Bildgröße. Die fehlenden Pixel einer Vergrößerung müssen interpoliert werden.
\item \textbf{Fensterung}\\
	Mit Hilfe der Fensterung werden die Grauwerte entsprechend den Werten von Window Width und Window Center auf den Bereich von 0 - 255 abgebildet.
\item \textbf{Bild zeichnen}\\
	Nachdem alle notwendigen Werte berechnet und die Grauwerte durch die Fensterung bestimmt wurden, kann das Bild auf der Zeichenfläche abgebildet werden.
\item \textbf{Informationen zeichnen}\\
	Der nächste Schritt ist das Zeichnen zusätzlicher Informationen für den Anwender. Hierzu zählen zum Beispiel die Koordinatenachsen oder die Werte zu Window Width und Window Center, Bildgröße sowie die Orientierungslinien.
\item \textbf{Hooks}\\
	Beide Hooks stellen Einhängepunkte für Werkzeuge dar. Das sind abstrakte Funktionen, die von konkreten Werkzeugen implementiert werden. Jeweils vor den Berechnungen und nach Abschluss des Zeichenvorgangs werden diese Funktionen aufgerufen und ausgeführt. So könnten zum Beispiel je nach Werkzeug zusätzliche Informationen eingezeichnet werden.
\end{enumerate}

Die Bereiche der Koordinatenberechnung, Interpolation und das Zeichnen der Informationen werden in den folgenden Abschnitten genauer erläutert. Die Initialisierung und das Zeichnen des Bildes sind einfache Operationen. Die Fensterung entspricht dem Algorithmus \ref{windowing_algo} aus Abschnitt \ref{windowing}.

\subsection{Berechnung der Bildkoordinaten}
Die Werkzeuge zur Translation und Skalierung beeinflussen die Koordinaten des Bildes. Während das Verschieben unproblematisch für die Performance der Anwendung ist, hat die Skalierung, im Besonderen die Vergrößerung, maßgeblichen Einfluss auf die Rechenzeit. Angenommen die Zeichenfläche hat eine Größe von $500 \times 500$ und $250.000$ Pixel und das Bild mit den Maßen $1000 \times 1000$  und $1.000.000$ Pixel die doppelte Größe. Daraus folgt, dass maximal $\frac{1}{4}$ der Pixel des Bildes auf der Zeichenfläche angezeigt werden können. Die sechs Blöcke des Prozesses verarbeiten auch die nicht sichtbaren Anteile des Bildes und verbrauchen dadurch unnötig Rechenzeit. In dem Beispiel bedeutet das einen Mehraufwand von $75\%$. Um diese zusätzliche Rechenzeit einzusparen, darf die Berechnung der Bildkoordinaten nur den aktuell sichtbaren Bereich in die Rechnungen einbeziehen.\\

\begin{figure*}[htb]
%\subfigure[Keypoints]{\includegraphics[width=0.49\textwidth]{./img/basmati_keypoints.png}}\hfill
\centering
\fbox{
\subfigure[Die Koordinaten eines Bildes]{\includegraphics[width=5cm]{./img/bildcoords.pdf} \label{coords:bild}}
\subfigure[Berechnung des sichtbaren Bereichs]{\includegraphics[width=5cm]{./img/offsetcoords.pdf} \label{coords:offset}}
\subfigure[Normalisierte Koordinaten]{\includegraphics[width=5cm]{./img/bildausschnitt.pdf} \label{coords:normal}}
}
\caption{Berechnung der Position und Koordinaten. Die graue Fläche symbolisiert das Bild und der rote Rahmen stellt den sichtbaren Bildausschnitt dar.}
\label{coords}
\end{figure*}

Wie Abbildung \ref{coords:bild} zeigt, bestimmt \textit{DicomCanvas} das Koordinatensystem mit der linken oberen Ecke als Ursprung. Die Position der Bilder wird durch vier Parameter bestimmt. Die Koordinaten $(x, y)$ legen den Ursprung des Bildes fest und $(widht, height)$ bestimmen mit Breite und Höhe die Dimension. Die tatsächlichen Koordinaten des Bildes sind dadurch $(x, y)$ und $(x+width, y+height)$. Liegen diese vier Parameter außerhalb der Zeichenfläche wie in Abbildung \ref{coords:offset}, muss der Abstand (offset) von x, y, width und height zum Canvas berechnet werden.\\
Das \textit{DicomCanvas} speichert nur das Originalbild und den aktuell sichtbaren Bildausschnitt. Da bei skalierten Bildern nur die Dimension und nicht die Pixeldaten hinterlegt sind, muss der sichtbare Bereich aus dem Original interpoliert werden. Um die richtigen Pixelwerte zu finden, wird mit normalisierten Koordinaten zwischen den Werten $(0, 0)$ für $(x,y)$ und $(1, 1)$ für $(x+width, y+height)$ gearbeitet. Abbildung \ref{coords:normal} zeigt ein Bild mit der Dimension $512 \times 512$, das um den Faktor vier auf $2048\times2048$ vergrößert wurde. Der sichtbare Bildausschnitt erstreckt sich von $(512, 512)$ bis $(1536, 1536)$. Das entspricht dem Bereich von $(128, 128)$ bis $(384, 384)$ im Originalbild. Mit Hilfe der normalisierten Koordinaten lassen sich die Bildbereiche bei gleichem Seitenverhältnis von Original und skaliertem Bild unabhängig von der Größe bestimmen. Für den Bildausschnitt im Beispiel entspricht der Bereich in normalisierter Darstellung $(0.25, 0.25)$ für $(x,y)$ und $(0.75, 0.75)$ für $(width, height)$. Mit gegebenen Pixelwerten lassen sich die normalisierten Koordinaten wie folgt bestimmen.

\begin{equation}
 x_{norm} = \frac{x}{width} \qquad
 y_{norm} = \frac{y}{height}
\end{equation}

Entsprechend dieser Gleichung erfolgt die Berechnung der Indizes von x und y.

\begin{equation}
 x = x_{norm} \cdot width \qquad
 y = y_{norm} \cdot height
\end{equation}

Mit diesen Hilfsmitteln lässt sich nun der obere linke und untere rechte Abstand des Bildes zur Zeichenfläche bestimmen. Zuerst wird geprüft ob $x$ und/oder $y$ einen Wert \textless 0 haben. Ist dies der Fall folgt daraus, dass das Bild aus der oberen und/oder linken Ecke der Zeichenfläche ragt. Die normalisierten Koordinaten lassen sich mit der Formel

\begin{equation}
 x_{norm} = \frac{|x|}{width} \qquad
 y_{norm} = \frac{|y|}{height}
\end{equation}

ermitteln. $x$ und $y$ sind der Abstand vom Ursprung des Koordinatensystems zum Ursprung des Bildes und somit nicht Teil des sichtbaren Bildausschnittes. Der Betrag ist notwendig, da nur Werte zwischen 0 und 1 als normalisierte Koordinaten akzeptiert werden.\\
Angenommen es existiert das Bild aus dem Beispiel in Abbildung \ref{coords:normal} mit den Koordinaten $(-512, -512)$, $(1536, 1536)$ und einer Dimension $(width, height)$ von $()2048, 2048)$ sowie eine Zeichenfläche mit der Dimension $(0, 0)$ und $(1024, 1024)$, dann ergeben sich daraus folgende normalisierte Koordinaten:

\begin{equation}
 x_{norm} = \frac{|-512|}{2048} = 0.25\qquad
 y_{norm} = \frac{|-512|}{2048} = 0.25
\end{equation}

Sind $x$ und/oder $y$ \textgreater= 0 folgt daraus, dass die obere linke Ecke des Bildes vollständig zu sehen ist. Das entspricht dem normalisierten Werten $(0, 0)$.\\
Der nächste Schritt ist die Prüfung der unteren Rechten Ecke. Bevor die Koordinaten bestimmt werden, muss der Abstand berechnet werden, da dieser nicht wie bei $x$ und $y$ abgelesen werden kann. Durch Subtraktion der Bildkoordinaten $(x+width, y+height)$ von der Zeichenfläche erhält man den Abstand zwischen Bild und Canvas.

\begin{equation}
 offset_{width} = x + width - width_{Canvas}\qquad
 offset_{height} = y + height - height_{Canvas}
\end{equation}

Subtrahiert man den Abstand von der Bilddimension erhält man die tatsächlichen Koordinaten, die noch im sichtbaren Bereich der Zeichenfläche liegen. Damit lassen sich die normalisierten Koordinaten berechnen.

\begin{equation}
 x_{norm} = \frac{width - offset_{width}}{width} \qquad
 y_{norm} = \frac{height - offset_{height}}{height}
\end{equation}

Für die Daten aus dem Beispiel ergeben sich folgende Werte:
\begin{equation}
 offset_{width} = -512 + 2048 -1024 = 512\qquad
 offset_{height} = -512 + 2048 -1024 = 512
\end{equation}

\begin{equation}
 x_{norm} = \frac{2048 - 512}{2048} = 0.75\qquad
 y_{norm} = \frac{2048 - 512}{2048} = 0.75
\end{equation}

Mit den berechneten Werten der normalisierten Koordinaten $(0.25, 0.25)$ und $(0.75, 0.75)$ lässt sich der zu interpolierende Bereich aus dem Originalbild bestimmen.

\begin{equation}
 x_1 = 0.25 \cdot 512 =  128\qquad
 y_1 = 0.25 \cdot 512 =  128
\end{equation}

\begin{equation}
 x_2 = 0.75 \cdot 512 =  384\qquad
 y_2 = 0.75 \cdot 512 =  384
\end{equation}

\subsection{Bilineare Interpolation}

Es können verschiedene Interpolationsmethoden eingesetzt werden, um das Bild oder einen Bildausschnitt zu vergrößern oder zu verkleinern. Die Abbildungen \ref{interpolation} zeigen die Ergebnisse einer Nearest Neighbor, biliniearer und bikubischen Interpolation. Das Nearest Neighbor Verfahren stellt die schnellste Interpolationsmethode dar, liefert allerdings auch gleichzeitig die schlechtesten Ergebnisse. In Abbildung \ref{interpolation:nn} erkennt man deutlich die Stufenbildung im Bild.\\
Bessere Ergebnisse liefert die bilineare Interpolation bei einer moderaten Laufzeit. Eine nochmals verbesserte Darstellung kann durch die bikubische Interpolation erreicht werden, benötigt allerdings den größten Rechenaufwand. Die bilinieare Methode liefert einen guten Kompromiss aus Qualität des skalierten Bildes und benötigte Rechenzeit.

\begin{figure*}[htb]
%\subfigure[Keypoints]{\includegraphics[width=0.49\textwidth]{./img/basmati_keypoints.png}}\hfill
\centering
\fbox{
\subfigure[Der rote Rahmen stellt den vergrößerten Ausschnitt aus den Abbildungen \ref{interpolation:nn}, \ref{interpolation:bilinear} und \ref{interpolation:bicubic} dar.]{\includegraphics[width=3.6cm]{./img/interpol_src.png} \label{interpolation:src}}
\subfigure[Nearest Neighbor Interpolation]{\includegraphics[width=3.6cm]{./img/nn_interpol.png} \label{interpolation:nn}}
\subfigure[Bilineare Interpolation]{\includegraphics[width=3.6cm]{./img/bilin.png} \label{interpolation:bilinear}}
\subfigure[Bikubische Interpolation]{\includegraphics[width=3.6cm]{./img/bicubic.png} \label{interpolation:bicubic}}
}
\caption{Vergleich der Nearest Neighbor, bilinearen und bikubischen Interpolation}
\label{interpolation}
\end{figure*}

Bei der bilinearen Interpolation werden die zu der Koordinate $(x_0, y_0)$ nächstliegenden vier Werte der Bildpunkte des Originalbildes zur Interpolation verwendet\cite[S.387]{burger:bv}. In Abbildung \ref{bilinear_interpolation} sind das \textit{A}, \textit{B}, \textit{C} und \textit{D}. Zuerst findet eine Interpolation in x-Richtung statt. Daraus ergeben sich die Werte \textit{E} und \textit{F}. Durch die Interpolation in y-Richtung der Werte \textit{E} und \textit{F} wird der finale Wert \textit{G} ermittelt.

\begin{figure}[htbp]
  \vspace{0.5cm}
  \centering
  \fbox{\includegraphics[angle=0,width=10cm]{./img/bilinear_interpolation.pdf}}
   \caption{Bilineare Interpolation \cite[S.388]{burger:bv}}
  \label{bilinear_interpolation}
  \vspace{0.5cm}
\end{figure}

Für jeden Bildpunkt des Zielbildes \textit{Z} wird der Referenzpunkt im Originalbild \textit{S} mittels einer Normalisierung gefunden.

\begin{equation}
 x_{0} = \frac{x_{Z}}{width_{Z}}\cdot width_{S}\qquad
 y_{0} = \frac{y_{Z}}{height_{Z}}\cdot height_{S}
\end{equation}

Zu den Werten von $x_{0}$ und $y_{0}$ müssen nach Burger und Burge\cite[S. 387 ff]{burger:bv} die nächstliegenden Bildwerte ermittelt werden.

\begin{equation}
A= S(x,y) \qquad B=S(x+1,y) \qquad C=S(x,y+1)\qquad D=S(x+1,y+1)
\end{equation}

wobei $x$ und $y$ die abgerundeten Werte von $x_{0}$ und $y_{0}$ darstellen. Die Werte \textit{E} und \textit{F} werden durch den Abstand von $x_{0}$ und $x$ ermittelt.

\begin{equation}
E = A + (x_0 - x) \cdot (B - A)
\end{equation}
\begin{equation}
F = C + (x_0 - x) \cdot (D-C)
\end{equation}

Nach der horizontalen Interpolation wird der finale Wert \textit{G} aus dem Abstand von $y_0$ und $y$ berechnet.

\begin{equation}
G = E + (y_0 - y) \cdot (F-E)
\end{equation}

Der Wert von \textit{G} kann nun beim Zielbild \textit{Z} an die aktuelle Position gesetzt werden. Bei Farbbildern wird jeder Kanal separat interpoliert.

\subsection{Anzeige der Zusatzinformationen}

Dem Benutzer werden direkt auf der Zeichenfläche wichtige Zusatzinformationen angezeigt. So kann der Anwender die aktuelle Größe des Bildes in Pixeln und das prozentuale Verhältnis zum Originalbild ablesen, sowie die gewählten Fensterungswerte einsehen. Neben den Bildeigenschaften werden auch dynamische Inhalte angezeigt wie das Patientenkoordinatensystem und Orientierungslinien. Orientierungslinien markieren in gleichen geöffneten 3D-Datensätzen mit unterschiedlicher Ebenenansicht einen gemeinsamen Punkt. Diese dynamischen Aspekte werden folgend erläutert.

\subsubsection{Das Koordinatensystem}

Der DICOM-Standard definiert ein sogenanntes \textit{Reference Coordinate System} \cite[S. 55]{dicom:iod} und dient zur Orientierung des Patienten im Raum. Es werden sechs Richtungen der drei Achsen definiert, womit die Lage des Patienten beschrieben werden kann \cite[C.7.6.1.1.1]{dicom:iod}. 

\begin{itemize}
\item \textbf{R} (right) - \textbf{L} (left) - \textbf{x} \\
	Right bestimmt die rechte, left die linke Hand des Patienten.
\item \textbf{A} (anterior) - \textbf{P} (posterior) - \textbf{y} \\
   Die Vorderseite des Patienten wird als Anterior, die Rückseite als Posterior bezeichnet.
\item \textbf{F} (foot) - \textbf{H} (head) - \textbf{z} \\
 Foot steht für den Patientenfuß und Head für den Kopf.
\end{itemize}

\begin{figure*}[htb]
%\subfigure[Keypoints]{\includegraphics[width=0.49\textwidth]{./img/basmati_keypoints.png}}\hfill
\centering
\fbox{
\subfigure[Die x- und z-Achse]{\includegraphics[width=7cm]{./img/coords1.pdf} \label{coords:xz}}
\subfigure[Die y- und z-Achse]{\includegraphics[width=7cm]{./img/coords2.pdf} \label{coords:yz}}
}
\caption{Das patientenbasierte Koordinatensystem}
\label{coords:both}
\end{figure*}

Wie in Abbildung \ref{coords:xz} dargestellt, steigt die x-Achse in Richtung der linken Hand das Patienten. Die Werte der y-Achse nehmen von der Vorderseite zur Rückseite des Patienten zu. Die z-Achse erhöht sich in Richtung der Füße zum Kopf des Patienten\cite[C.7.6.2.1.1]{dicom:iod}.\\
Unter Berücksichtigung des DICOM-Tags \textit{Image Orientation} mit dessen Vektoren kann die Beschriftung der Koordinatenachsen bestimmt werden. Durch den maximalen Betrag der Elemente der Vektoren wird die dominanten Achsen ermittelt. Dadurch erhält man die Koordinatenachsen der Bildebene. Des weiteren kann durch die Achsen die Ebenendarstellung bestimmt werden. Ein dominanter xy-Anteil bedeutet \textit{axiale} Ebenendarstellung, der xz-Anteil ist die \textit{coronale} Ansicht und der yz-Anteil die \textit{sagittale} Darstellung.

\begin{equation}
\vec{r}=\left(\begin{array}{c} 1 \\ 0 \\ 0 \end{array}\right) \qquad
\vec{c}=\left(\begin{array}{c} 0 \\ 1 \\ 0 \end{array}\right)
\vspace{0.5cm}
\label{orientationvecs}
\end{equation}

Beispiel \ref{orientationvecs} zeigt zwei Vektoren von \textit{ImageOrientation}. Die dominanten Achsen sind das x-Element aus $\vec{r}$ mit dem Wert $1$ und das y-Element aus $\vec{c}$ ebenfalls mit $1$. Durch den dominanten Anteil können die Achsen abgelesen werden, die auf die Bildebene gezeichnet werden. Die x-Achse bekommt auf der negativen Seite \textit{R} und \textit{L} auf der positiven Seite. Die zweite Achse der Bildebene ist y mit der negativen Seite \textit{A} und positiver Seite \textit{P}. Die z-Achse mit \textit{H} und \textit{F} ragt aus der Bildebene heraus beziehungsweise hinein. Sind die Elemente negativ ist die Richtung der Koordinatenachsen vertauscht. Aus den Beispielvektoren ergibt sich folgende Darstellung der Achsen wie in Abbildung \ref{axialbsp} dargestellt.

\begin{figure}[htbp]
  \vspace{0.5cm}
  \centering
  \fbox{\includegraphics[angle=0,width=6cm]{./img/axialbsp.pdf}}
   \caption{Beschriftung der Koordinatenachsen bei axialer Ebenendarstellung}
  \label{axialbsp}
  \vspace{0.5cm}
\end{figure}

\subsubsection{Zeichnen der Orientierungslinien}

Wenn mehrerer gleiche Datensätze in unterschiedlichen Ebenendarstellungen geöffnet sind, helfen dem Anwender die Orientierungslinien bei der Navigation durch den dreidimensionalen Datensatz. Abbildung \ref{lines:single:a} zeigt eine axiale Ebenedarstellung als aktuelle Anzeige, die vom Benutzer bedient wird. Zusätzlich sind die coronale (Abbildung \ref{lines:c}) und sagittale Ansicht (Abbildung \ref{lines:s}) geöffnet. Da der Anwender in der axialen Ansicht arbeitet, werden Änderungen der Bildanzeige an die beiden Beobachter weitergegeben.\\
Navigiert der Nutzer mit der Scrollleiste durch den axialen Datensatz, wird mit Hilfe des Oberserver-Musters bei jeder Änderung die aktuelle z-Koordinate der Bildschicht an die coronale und sagittale Darstellung übertragen. Dieser z-Wert wird an der entsprechenden Stelle der Bildschicht als, im Beispiel blaue, Orientierungslinie eingezeichnet. \\
Wie in den Abbildungen \ref{lines:single} zu sehen ist, entspricht die z-Koordinate in axialer Ansicht der y-Koordinate der coronalen und sagittalen Darstellung. Daraus folgt, dass die Orientierungslinie an der Stelle von $(0, y_{coronal}) $ bis $(width, y_{coronal})$ sowie von $(0, y_{sagittal}) $ bis $(width, y_{sagittal})$ für $y_{coronal}, y_{sagittal} = z_{axial}$

\begin{figure*}[htb]
%\subfigure[Keypoints]{\includegraphics[width=0.49\textwidth]{./img/basmati_keypoints.png}}\hfill
\centering
\fbox{
\subfigure[Axiale Ebenendarstellung]{\includegraphics[width=5cm]{./img/lines_axial_single.pdf} \label{lines:single:a}}
\subfigure[Orientierungslinie der axialen Darstellung in der coronalen Ebenendarstellung]{\includegraphics[width=5cm]{./img/lines_coronal_single.pdf} \label{lines:single:c}}
\subfigure[Orientierungslinie der axialen Darstellung in der sagittalen Ebenendarstellung]{\includegraphics[width=5cm]{./img/lines_sagittal_single.pdf} \label{lines:single:s}}
}
\caption{Einfache Darstellung der Orientierungslinien}
\label{lines:single}
\end{figure*}

Die Koordinaten zum Einzeichnen der Orientierungslinien sind abhängig von der Quell- und Zieldarstellung. Navigiert der Anwender in der sagittalen Ebenendarstellung und aktualisiert damit eine axiale Anzeige entspricht die Koordinate $z_{sagittal}  = x_{axial}$. Die Orientierungslinie wird damit durch die Punkte $(x_{axial}, 0) $ und $(x_{axial}, height)$ definiert. Diese Vorgehensweise wird bei einer Navigation mit der Scrollleiste umgesetzt. Eine weitere Möglichkeit zur Orientierung im Datensatz ist die direkte Auswahl eines Punktes.

\begin{figure*}[htb]
%\subfigure[Keypoints]{\includegraphics[width=0.49\textwidth]{./img/basmati_keypoints.png}}\hfill
\centering
\fbox{
\subfigure[Punktauswahl in axialer Ebenendarstellung]{\includegraphics[width=5cm]{./img/lines_axial.pdf} \label{lines:a}}
\subfigure[Anzeige des referenzierten Punktes aus der axialen Darstellung in der coronalen Ebene]{\includegraphics[width=5cm]{./img/lines_coronal.pdf} \label{lines:c}}
\subfigure[Anzeige des referenzierten Punktes aus der axialen Darstellung in der sagittalen Ebene]{\includegraphics[width=5cm]{./img/lines_sagittal.pdf} \label{lines:s}}
}
\caption{Anzeige eines referenzierten Punktes in axialer Ebene mit Hilfe der Orientierungslinien}
\label{lines}
\end{figure*}

Abbildung \ref{lines:a} zeigt einen vom Anwender gewählten Punkt in der axialen Darstellung. Wieder müssen alle Beobachter, also Bildanzeigen mit dem gleichen Datensatz, nach der Auswahl aktualisiert werden. Die Abbildungen \ref{lines:single} zeigen nur die aktuell vom Nutzer gewählte Bildschicht der aktiven Anzeige. Bei einer direkten Punktauswahl wird in allen Ansichten der gleiche Punkt im Raum $(x, y, z)$ referenziert. Das bedeutet, es werden sowohl die horizontale, als auch die vertikale Orientierungslinie eingezeichnet. Zusätzlich wird die angezeigte Bildschicht der Beobachter den Koordinaten angepasst. Der gewählte Punkt wird jeweils durch den Schnittpunkt der Orientierungslinien symbolisiert. Das Beispiel der Abbildungen in \ref{lines} zeigt eine aktive axiale Ansicht sowie eine coronale und sagittale Ebenendarstellung als Beobachter.\\
Der vom Anwender gewählte Punkt im Raum ist:

\begin{equation}
P_{axial}=\left(\begin{array}{c} x_{axial} \\ y_{axial} \\ z_{axial} \end{array}\right) 
\vspace{0.5cm}
\end{equation}
Aus diesem Punkt müssen die Koordinaten für die Orientierungslinien und der Bildschicht bestimmt werden.
Für die Darstellung von der axialen Ansicht zum referenzierten coronalen Punkt folgt aus Abbildung \ref{lines:c}:
\begin{equation}
P_{coronal}=\left(\begin{array}{c} x_{coronal} \\ y_{coronal} \\ z_{coronal} \end{array}\right) =
\left(\begin{array}{c} x_{axial} \\ z_{axial} \\ y_{axial} \end{array}\right)
\vspace{0.5cm}
\end{equation}

Mit diesen Koordinaten ergeben sich für die coronale Ebenendarstellung die vertikale Orientierungslinie von $(x_{axial}, 0)$ bis $(x_{axial}, height)$, die horizontale Linie $(0, z_{axial})$ bis $(width, z_{axial})$ und der Index der Bildschicht $y_{axial}$.\\
Auch dieses Vorgehen ist abhängig von der Quell- und Zieldarstellung der aktiven Darstellung und Beobachtern.

\subsection{Implementierung der Werkzeuge}

Die Anzeige der Orientierungslinien komplettiert die Funktionalitäten zur Bilddarstellung, Navigation und Orientierung. Der nächste Schritt befasst sich mit der Manipulation der Bilddaten mit den zur Verfügung gestellten Werkzeugen.

\subsubsection{Das Bild bewegen mit dem MoveTool}

\subsubsection{Skalierung mit dem ResizeTool}

\subsubsection{Justierung der Fensterung mit dem WindowTool}

\subsubsection{Punktauswahl mit dem PointTool}

\section{Das Utility-Fenster}

\subsection{Debugging mit dem ConsoleView}

\subsection{DICOM-Objekte über DicomTagView ausgeben}

\section{Implementierung des Hauptmenüs und der Werkzeugleiste}

\subsection{Das Hauptmenü}

\subsection{Die Werkzeugleiste}



